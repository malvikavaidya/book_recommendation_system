{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nidhi\\AppData\\Local\\Temp\\ipykernel_11984\\2349466462.py:11: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"/usr/lib/chromium-browser/chromedriver\", chrome_options=options)\n",
      "C:\\Users\\nidhi\\AppData\\Local\\Temp\\ipykernel_11984\\2349466462.py:11: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(\"/usr/lib/chromium-browser/chromedriver\", chrome_options=options)\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "from urllib.request import urlopen, Request\n",
    "from selenium import webdriver\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(\"/usr/lib/chromium-browser/chromedriver\", chrome_options=options)\n",
    "\n",
    "# f = open(\"book_titles.txt\", \"x\")\n",
    "# f2 = open(\"book_descriptions.txt\", \"x\")\n",
    "# f3 = open(\"book_genres.txt\", \"x\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "book_titles = []\n",
    "book_descriptions = []\n",
    "book_genres = []\n",
    "book_authors = []\n",
    "\n",
    "page_link = \"https://www.goodreads.com/list/show/4093.Best_Books_of_the_Decade_2010s?page=1\"\n",
    "# driver.get(page_link)\n",
    "# soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "page = requests.get(page_link, headers=headers)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "idx = 0\n",
    "for i in range(1):\n",
    "    books = soup.find_all('a', class_='bookTitle')\n",
    "    \n",
    "    for i in books:\n",
    "        link = \"https://goodreads.com\" + i['href']\n",
    "        time.sleep(1)\n",
    "        resp = requests.get(link, headers=headers)\n",
    "\n",
    "        book_soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "        # print(book_soup)\n",
    "        description = book_soup.find(class_=\"DetailsLayoutRightParagraph__widthConstrained\")\n",
    "        if description == None:\n",
    "            if book_soup.find(class_=\"readable stacked\") == None:\n",
    "                print(\"No description\")\n",
    "                description = \"No description\"\n",
    "            else:\n",
    "                description = book_soup.find(class_=\"readable stacked\").find('span', style=\"display:none\").get_text()\n",
    "            \n",
    "        else:\n",
    "            description = description.text\n",
    "            \n",
    "        book_descriptions.append(description)\n",
    "        \n",
    "        book_titles.append(book_soup.find(\"meta\", property=\"og:title\").get('content'))\n",
    "        genre_buttons = []\n",
    "    \n",
    "        genre_buttons = book_soup.find_all(class_=\"actionLinkLite bookPageGenreLink\")\n",
    "        if(len(genre_buttons) == 0):\n",
    "            genre_buttons = book_soup.find_all(class_='BookPageMetadataSection__genreButton')\n",
    "    \n",
    "        single_book_genres = []\n",
    "        genre_i = 0\n",
    "        for j in genre_buttons:\n",
    "            if(genre_i == 5):\n",
    "                break\n",
    "            single_book_genres.append(j.text)\n",
    "            genre_i += 1\n",
    "        book_genres.append(single_book_genres)\n",
    "        if idx == 5:\n",
    "            break\n",
    "        idx += 1\n",
    "       \n",
    "        author_name = book_soup.find(class_=\"authorName\")\n",
    "        if author_name == None:\n",
    "            if book_soup.find(class_=\"ContributorLink__name\") == None:\n",
    "                author_name = \"No author\"\n",
    "                break\n",
    "            author_name = book_soup.find(class_=\"ContributorLink__name\").get_text()\n",
    "        else:\n",
    "            author_name = author_name.get_text()\n",
    "        book_authors.append(author_name)\n",
    "        \n",
    "\n",
    "    page_link = 'https://goodreads.com' + soup.find('a', class_='next_page').get('href')\n",
    "    # driver.get(page_link)\n",
    "    # soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    page = requests.get(page_link, headers=headers)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Fault in Our Stars', 'Divergent (Divergent, #1)', 'Mockingjay (The Hunger Games, #3)', 'Gone Girl', 'The Martian', 'All the Light We Cannot See']\n",
      "[\"Despite the tumor-shrinking medical miracle that has bought her a few years, Hazel has never been anything but terminal, her final chapter inscribed upon diagnosis. But when a gorgeous plot twist named Augustus Waters suddenly appears at Cancer Kid Support Group, Hazel's story is about to be completely rewritten.Insightful, bold, irreverent, and raw, The Fault in Our Stars is award-winning author John Green's most ambitious and heartbreaking work yet, brilliantly exploring the funny, thrilling, and tragic business of being alive and in love.\", \"In Beatrice Prior's dystopian Chicago world, society is divided into five factions, each dedicated to the cultivation of a particular virtue—Candor (the honest), Abnegation (the selfless), Dauntless (the brave), Amity (the peaceful), and Erudite (the intelligent). On an appointed day of every year, all sixteen-year-olds must select the faction to which they will devote the rest of their lives. For Beatrice, the decision is between staying with her family and being who she really is—she can't have both. So she makes a choice that surprises everyone, including herself.During the highly competitive initiation that follows, Beatrice renames herself Tris and struggles alongside her fellow initiates to live out the choice they have made. Together they must undergo extreme physical tests of endurance and intense psychological simulations, some with devastating consequences. As initiation transforms them all, Tris must determine who her friends really are—and where, exactly, a romance with a sometimes fascinating, sometimes exasperating boy fits into the life she's chosen. But Tris also has a secret, one she's kept hidden from everyone because she's been warned it can mean death. And as she discovers unrest and growing conflict that threaten to unravel her seemingly perfect society, she also learns that her secret might help her save those she loves . . . or it might destroy her.\", \"My name is Katniss Everdeen.Why am I not dead?I should be dead.Katniss Everdeen, girl on fire, has survived, even though her home has been destroyed. Gale has escaped. Katniss's family is safe. Peeta has been captured by the Capitol. District 13 really does exist. There are rebels. There are new leaders. A revolution is unfolding.It is by design that Katniss was rescued from the arena in the cruel and haunting Quarter Quell, and it is by design that she has long been part of the revolution without knowing it. District 13 has come out of the shadows and is plotting to overthrow the Capitol. Everyone, it seems, has had a hand in the carefully laid plans—except Katniss.The success of the rebellion hinges on Katniss's willingness to be a pawn, to accept responsibility for countless lives, and to change the course of the future of Panem. To do this, she must put aside her feelings of anger and distrust. She must become the rebels' Mockingjay—no matter what the personal cost.\", \"Who are you?What have we done to each other?These are the questions Nick Dunne finds himself asking on the morning of his fifth wedding anniversary when his wife Amy suddenly disappears. The police suspect Nick. Amy's friends reveal that she was afraid of him, that she kept secrets from him. He swears it isn't true. A police examination of his computer shows strange searches. He says they weren't made by him. And then there are the persistent calls on his mobile phone.So what did happen to Nick's beautiful wife?\", 'Six days ago, astronaut Mark Watney became one of the first people to walk on Mars. Now, he’s sure he’ll be the first person to die there.After a dust storm nearly kills him and forces his crew to evacuate while thinking him dead, Mark finds himself stranded and completely alone with no way to even signal Earth that he’s alive—and even if he could get word out, his supplies would be gone long before a rescue could arrive. Chances are, though, he won’t have time to starve to death. The damaged machinery, unforgiving environment, or plain-old “human error” are much more likely to kill him first. But Mark isn’t ready to give up yet. Drawing on his ingenuity, his engineering skills — and a relentless, dogged refusal to quit — he steadfastly confronts one seemingly insurmountable obstacle after the next. Will his resourcefulness be enough to overcome the impossible odds against him?', 'Marie-Laure lives in Paris near the Museum of Natural History, where her father works. When she is twelve, the Nazis occupy Paris and father and daughter flee to the walled citadel of Saint-Malo, where Marie-Laure’s reclusive great uncle lives in a tall house by the sea. With them they carry what might be the museum’s most valuable and dangerous jewel.In a mining town in Germany, Werner Pfennig, an orphan, grows up with his younger sister, enchanted by a crude radio they find that brings them news and stories from places they have never seen or imagined. Werner becomes an expert at building and fixing these crucial new instruments and is enlisted to use his talent to track down the resistance. Deftly interweaving the lives of Marie-Laure and Werner, Doerr illuminates the ways, against all odds, people try to be good to one another.From the highly acclaimed, multiple award-winning Anthony Doerr, the stunningly beautiful instant New York Times bestseller about a blind French girl and a German boy whose paths collide in occupied France as both try to survive the devastation of World War II.An alternate cover for this ISBN can be found here']\n",
      "[['Young Adult', 'Romance', 'Fiction', 'Contemporary', 'Realistic Fiction'], ['Young Adult', 'Dystopia', 'Fiction', 'Fantasy', 'Science Fiction'], ['Young Adult', 'Dystopia', 'Fiction', 'Fantasy', 'Science Fiction'], ['Fiction', 'Mystery', 'Thriller', 'Thriller', 'Mystery Thriller'], ['Science Fiction', 'Fiction', 'Audiobook', 'Adventure', 'Space'], ['Historical', 'Historical Fiction', 'Fiction', 'Historical', 'War']]\n",
      "['John Green', 'Veronica Roth', 'Suzanne Collins', 'Gillian Flynn', 'Andy Weir']\n"
     ]
    }
   ],
   "source": [
    "# f = open(\"book_titles.txt\", \"w\")\n",
    "# f2 = open(\"book_descriptions.txt\", \"w\")\n",
    "# f3 = open(\"book_genres.txt\", \"w\")\n",
    "\n",
    "# f.write(book_titles)\n",
    "# f.close()\n",
    "# f2.write(book_descriptions)\n",
    "# f2.close()\n",
    "# f3.write(book_genres)\n",
    "# f3.close()\n",
    "print(book_titles)\n",
    "print(book_descriptions)\n",
    "print(book_genres)\n",
    "print(book_authors)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import contractions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import string\n",
    "def clean_text(text):\n",
    "    # remove numbers\n",
    "    text_nonum = re.sub(r'\\d+', '', text)\n",
    "    # remove punctuations and convert characters to lower case\n",
    "    text_nopunct = \"\"\n",
    "    for char in text_nonum:\n",
    "        if char not in string.punctuation:\n",
    "            text_nopunct += char.lower()\n",
    "        else:    \n",
    "            text_nopunct += \" \"\n",
    "    # substitute multiple whitespace with single whitespace\n",
    "    # Also, removes leading and trailing whitespaces\n",
    "    text_no_doublespace = re.sub('\\s+', ' ', text_nopunct).strip()\n",
    "    return text_no_doublespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = []\n",
    "for description in book_descriptions:\n",
    "    descrption = contractions.fix(description)\n",
    "    description = clean_text(description)\n",
    "    tokens = word_tokenize(description)\n",
    "    tokenized.append(tokens)\n",
    "\n",
    "tokenized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered = []\n",
    "\n",
    "for word_tokens in tokenized:\n",
    "    filtered_sentence = []\n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words and w != \"s\":\n",
    "            filtered_sentence.append(w)\n",
    "    filtered.append(filtered_sentence)\n",
    "\n",
    "filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemma_descriptions = []\n",
    "for description in filtered:\n",
    "    lemma = []\n",
    "    for w in description:\n",
    "        #this is so jank\n",
    "        #ideally we would have to do POS tagging and then pass the actual tag to the function\n",
    "        w = lemmatizer.lemmatize(w,  'v')\n",
    "        lemma.append(lemmatizer.lemmatize(w,  'n'))\n",
    "    lemma_descriptions.append(lemma)    \n",
    "\n",
    "lemma_descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['despite tumor shrink medical miracle buy year hazel never anything terminal final chapter inscribe upon diagnosis gorgeous plot twist name augustus water suddenly appear cancer kid support group hazel story completely rewrite insightful bold irreverent raw fault star award win author john green ambitious heartbreaking work yet brilliantly explore funny thrill tragic business alive love ', 'beatrice prior dystopian chicago world society divide five faction dedicate cultivation particular virtue—candor honest abnegation selfless dauntless brave amity peaceful erudite intelligent appoint day every year sixteen year old must select faction devote rest live beatrice decision stay family really is—she make choice surprise everyone include highly competitive initiation follow beatrice rename tris struggle alongside fellow initiate live choice make together must undergo extreme physical test endurance intense psychological simulation devastate consequence initiation transform tris must determine friend really are—and exactly romance sometimes fascinate sometimes exasperate boy fit life choose tris also secret one keep hide everyone warn mean death discover unrest grow conflict threaten unravel seemingly perfect society also learn secret might help save love might destroy ', 'name katniss everdeen dead dead katniss everdeen girl fire survive even though home destroy gale escape katniss family safe peeta capture capitol district really exist rebel new leader revolution unfold design katniss rescue arena cruel haunt quarter quell design long part revolution without know district come shadow plot overthrow capitol everyone seem hand carefully lay plans—except katniss success rebellion hinge katniss willingness pawn accept responsibility countless live change course future panem must put aside feel anger distrust must become rebel mockingjay—no matter personal cost ', 'do question nick dunne find ask morning fifth wed anniversary wife amy suddenly disappear police suspect nick amy friend reveal afraid keep secret swear true police examination computer show strange search say make persistent call mobile phone happen nick beautiful wife ', 'six day ago astronaut mark watney become one first people walk mar ’ sure ’ first person die dust storm nearly kill force crew evacuate think dead mark find strand completely alone way even signal earth ’ alive—and even could get word supply would go long rescue could arrive chance though ’ time starve death damage machinery unforgiving environment plain old “ human error ” much likely kill first mark ’ ready give yet draw ingenuity engineer skill — relentless dog refusal quit — steadfastly confront one seemingly insurmountable obstacle next resourcefulness enough overcome impossible odds ', 'marie laure live paris near museum natural history father work twelve nazi occupy paris father daughter flee wall citadel saint malo marie laure ’ reclusive great uncle live tall house sea carry might museum ’ valuable dangerous jewel mine town germany werner pfennig orphan grow younger sister enchant crude radio find bring news story place never see imagine werner become expert build fix crucial new instrument enlist use talent track resistance deftly interweave live marie laure werner doerr illuminate way odds people try good one another highly acclaim multiple award win anthony doerr stunningly beautiful instant new york time bestseller blind french girl german boy whose path collide occupy france try survive devastation world war ii alternate cover isbn find ']\n"
     ]
    }
   ],
   "source": [
    "text_to_vectorize = []\n",
    "for description in lemma_descriptions:\n",
    "    book_descrip = \"\"\n",
    "    for w in description:\n",
    "        book_descrip += w + \" \"\n",
    "    text_to_vectorize.append(book_descrip)\n",
    "print(text_to_vectorize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abnegation</th>\n",
       "      <th>accept</th>\n",
       "      <th>acclaim</th>\n",
       "      <th>afraid</th>\n",
       "      <th>ago</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "      <th>alongside</th>\n",
       "      <th>also</th>\n",
       "      <th>alternate</th>\n",
       "      <th>...</th>\n",
       "      <th>win</th>\n",
       "      <th>without</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>younger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112913</td>\n",
       "      <td>0.112913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.082479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082479</td>\n",
       "      <td>0.164957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.100849</td>\n",
       "      <td>0.082697</td>\n",
       "      <td>0.100849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068499</td>\n",
       "      <td>0.068499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>0.083534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abnegation    accept   acclaim  afraid       ago     alive     alone  \\\n",
       "0    0.000000  0.000000  0.000000  0.0000  0.000000  0.112913  0.000000   \n",
       "1    0.082479  0.000000  0.000000  0.0000  0.000000  0.000000  0.000000   \n",
       "2    0.000000  0.089774  0.000000  0.0000  0.000000  0.000000  0.000000   \n",
       "3    0.000000  0.000000  0.000000  0.1407  0.000000  0.000000  0.000000   \n",
       "4    0.000000  0.000000  0.000000  0.0000  0.100849  0.082697  0.100849   \n",
       "5    0.000000  0.000000  0.083534  0.0000  0.000000  0.000000  0.000000   \n",
       "\n",
       "   alongside      also  alternate  ...       win   without      word  \\\n",
       "0   0.000000  0.000000   0.000000  ...  0.112913  0.000000  0.000000   \n",
       "1   0.082479  0.164957   0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.000000   0.000000  ...  0.000000  0.089774  0.000000   \n",
       "3   0.000000  0.000000   0.000000  ...  0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.000000   0.000000  ...  0.000000  0.000000  0.100849   \n",
       "5   0.000000  0.000000   0.083534  ...  0.068499  0.000000  0.000000   \n",
       "\n",
       "       work     world     would      year       yet      york   younger  \n",
       "0  0.112913  0.000000  0.000000  0.112913  0.112913  0.000000  0.000000  \n",
       "1  0.000000  0.067634  0.000000  0.135267  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.000000  0.100849  0.000000  0.082697  0.000000  0.000000  \n",
       "5  0.068499  0.068499  0.000000  0.000000  0.000000  0.083534  0.083534  \n",
       "\n",
       "[6 rows x 394 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(text_to_vectorize)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)\n",
    "df\n",
    "\n",
    "#slayyyyy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
